{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DtsWoxMke3BT"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UpdYNGr3QHPG"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.ticker as plticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import io\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kNDGhEtlfe95"
   },
   "source": [
    "### Urls to scrape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c0UsCfqyUx2I"
   },
   "outputs": [],
   "source": [
    "#urls\n",
    "main_url='https://www.prokabaddi.com'\n",
    "stats_all = 'https://www.prokabaddi.com/stats'\n",
    "url_alt = 'https://www.sportskeeda.com/go/pro-kabaddi/stats'\n",
    "\n",
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit 537.36 (KHTML, like Gecko) Chrome\",\n",
    "           \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UXMNTIm1VSIa",
    "outputId": "8b1f8e6b-1c50-4c6d-d1de-1b68d9060edb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#Get the details from the main page of Pro kabaddi.\n",
    "\n",
    "response = requests.get(main_url, headers=headers)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cduW-8-Jge_i"
   },
   "source": [
    "### Extract links for all the team from main page of pro kabaddi and store into a csv file: 'team_links.csv' on local machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hOJS1bFwVXlU"
   },
   "outputs": [],
   "source": [
    "soup = bs(response.text, 'html.parser')\n",
    "df_team_links = pd.DataFrame()\n",
    "links = soup.find_all('a')\n",
    "\n",
    "team_links = [main_url + x.attrs['href'] for x in links[13:25]]\n",
    "team_name = [x.text for x in links[13:25]]\n",
    "df_team_links['team_name'] = team_name\n",
    "df_team_links['team_url_link'] = team_links\n",
    "df_team_links.to_csv('team_links.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\ravi\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\ravi\\anaconda3\\lib\\site-packages (from selenium) (1.24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** https://medium.com/shakuro/adopting-ipython-jupyter-for-selenium-testing-d02309dd00b8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "d = webdriver.Chrome(executable_path=r'C:\\webdrivers\\chromedriver.exe',chrome_options=chrome_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WtZiMe_AlP1x"
   },
   "source": [
    "### Extract team stats for each team and for every seasons and store into CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "QOtV4VfulZ8b",
    "outputId": "dc63434b-8c7f-4021-97cf-35b2f793bd78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.prokabaddi.com/teams/bengal-warriors-profile-4', 'https://www.prokabaddi.com/teams/bengaluru-bulls-profile-1', 'https://www.prokabaddi.com/teams/dabang-delhi-kc-profile-2', 'https://www.prokabaddi.com/teams/gujarat-fortunegiants-profile-31', 'https://www.prokabaddi.com/teams/haryana-steelers-profile-28', 'https://www.prokabaddi.com/teams/jaipur-pink-panthers-profile-3', 'https://www.prokabaddi.com/teams/patna-pirates-profile-6', 'https://www.prokabaddi.com/teams/puneri-paltan-profile-7', 'https://www.prokabaddi.com/teams/tamil-thalaivas-profile-29', 'https://www.prokabaddi.com/teams/telugu-titans-profile-8', 'https://www.prokabaddi.com/teams/u-mumba-profile-5', 'https://www.prokabaddi.com/teams/up-yoddha-profile-30']\n",
      "https://www.prokabaddi.com/teams/bengal-warriors-profile-4\n",
      "https://www.prokabaddi.com/teams/bengaluru-bulls-profile-1\n",
      "https://www.prokabaddi.com/teams/dabang-delhi-kc-profile-2\n",
      "https://www.prokabaddi.com/teams/gujarat-fortunegiants-profile-31\n",
      "https://www.prokabaddi.com/teams/haryana-steelers-profile-28\n",
      "https://www.prokabaddi.com/teams/jaipur-pink-panthers-profile-3\n",
      "https://www.prokabaddi.com/teams/patna-pirates-profile-6\n",
      "https://www.prokabaddi.com/teams/puneri-paltan-profile-7\n",
      "https://www.prokabaddi.com/teams/tamil-thalaivas-profile-29\n",
      "https://www.prokabaddi.com/teams/telugu-titans-profile-8\n",
      "https://www.prokabaddi.com/teams/u-mumba-profile-5\n",
      "https://www.prokabaddi.com/teams/up-yoddha-profile-30\n"
     ]
    }
   ],
   "source": [
    "ext_data = []\n",
    "i = 0\n",
    "print(team_links)\n",
    "for m in team_links:\n",
    "    time.sleep(5)\n",
    "    d.maximize_window()\n",
    "    html = d.page_source\n",
    "\n",
    "    soup_1 = bs(html, 'html.parser')\n",
    "    cols  = soup_1.find('div', {'class': 'si-team-stats'}).find('div', {'class': 'si-tbl-header'}).find_all('div', {'class': 'si-data-block'})\n",
    "    main_cols = [x.text for x in cols]\n",
    "    cols1 = soup_1.find('div', {'class': 'si-team-stats'}).find('div', {'class': 'si-overall'}).find_all('div', {'class': 'si-data-block'})\n",
    "    cols_x = [x.text for x in cols1]\n",
    "    cols2 = soup_1.find('div', {'class': 'si-team-stats'}).find('div', {'class': 'si-attack'}).find_all('div', {'class': 'si-data-block'})\n",
    "    cols2_l = [x.text for x in cols2]\n",
    "    cols3 = soup_1.find('div', {'class': 'si-team-stats'}).find('div', {'class': 'si-defence'}).find_all('div', {'class': 'si-data-block'})\n",
    "    cols3_l = [x.text for x in cols3]\n",
    "    main_cols = main_cols + cols_x + cols2_l + cols3_l\n",
    "    team_cols = ['team_name']\n",
    "    main_cols = team_cols + main_cols\n",
    "\n",
    "    datahead = soup_1.find('div', {'class': 'si-team-stats'}).find('div', {'class': 'si-right'}).find('div', {'class': 'si-tbl-header'}).find_all('div', {'class': 'si-data-block'})\n",
    "    datahead_t = [x.text for x in datahead]\n",
    "\n",
    "    data = []\n",
    "    for each1 in range(1,4):\n",
    "        list1 = []\n",
    "        for each in range(len(datahead_t)):\n",
    "            datahead1 = soup_1.find('div', {'class': 'si-team-stats'}).find('div', {'class': 'si-right'}).find_all('div', {'class': 'si-tbl-wraper'})[each1].find_all('div', {'class': 'si-tbl-data'})[each].find_all('div', {'class': 'si-data-block'})\n",
    "            datahead1_t = [x.text.strip('\\n').split('\\n')[0] for x in datahead1]\n",
    "            list1.append(datahead1_t)\n",
    "        data.append(list1)\n",
    "\n",
    "    newdata=[]\n",
    "    for each in range(len(data[0])):\n",
    "        newdata.append(data[0][each] + data[1][each] + data[2][each])\n",
    "\n",
    "    newdata1=[]\n",
    "    for each in range(len(newdata)):\n",
    "        temp = []\n",
    "        temp.append(team_name[i])\n",
    "        temp.append(datahead_t[each])\n",
    "        for inside in range(len(newdata[0])):\n",
    "            temp.append(newdata[each][inside])\n",
    "        newdata1.append(temp)\n",
    "\n",
    "    ext_data.append(newdata1)\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FfpwAqtTnVze"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\\'team_stats.csv\\', \\'w\\') as f:\\n  employee_writer = csv.writer(f, delimiter=\\',\\', quotechar=\\'\"\\', quoting=csv.QUOTE_MINIMAL)\\n  employee_writer.writerow([\\'TEAM NAME\\', \\'SEASONS\\',\\'MATCHES PLAYED\\',\\'WINS\\',\\'DRAWS\\',\\'LOSSES\\',\\'FINISHING POSITION\\',\\'HIGHEST SCORE\\',\\'BIGGEST WINNING MARGIN\\',\\n                              \\'TOTAL RAIDS\\',\\'SUCCESSFUL RAIDS\\',\\'UNSUCCESSFUL RAID\\',\\'EMPTY RAIDS\\',\\'SUCCESS RAID %\\',\\'NO. OF SUPER RAIDS\\',\\'RAID TOUCH POINTS\\',\\n                              \\'RAID BONUS POINTS\\',\\'TOTAL RAID POINTS\\'\\n                              \\'TOTAL TACKLES\\',\\'SUCCESSFUL TACKLES\\',\\'UNSUCCESFUL TACKLES\\',\\'SUCCESSFUL TACKLE %\\',\\'NO. OF SUPER TACKLES\\',\\'ALL OUTS INFLICTED\\',\\n                              \\'TOTAL ALL OUT POINTS\\',\\'TOTAL DEFENCE POINTS\\'])\\n\\n  for each in range(len(df_matches_det)):\\n    row1 = df_matches_det.iloc[each].values.flatten().tolist()\\n    #print(row1)\\n    employee_writer.writerow(row1)\\n    \\nfiles.download(\\'team_stats.csv\\')\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_data1 = []\n",
    "for each in ext_data:\n",
    "    ext_data1 = ext_data1 + each\n",
    "\n",
    "df_matches_det = pd.DataFrame(data=ext_data1, columns=main_cols)\n",
    "df_matches_det.head()\n",
    "df_matches_det.to_csv('team_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F93EJbP4h7AD"
   },
   "source": [
    "### Get All schedules and results of every match of Pro Kabaddi for all seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DGZir6DJiERt"
   },
   "outputs": [],
   "source": [
    "divhead = soup.find('div', {'class': 'nav-middle'})\n",
    "divli = divhead.find('li', {'class': 'schedule-fixtures-results'}).find('a').attrs['href']\n",
    "schedule_link = main_url + divli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "JNY-tH1tiVb4",
    "outputId": "ab4048e9-176f-4c2a-dda3-6b1726f47bff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(515, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.get(schedule_link)\n",
    "time.sleep(5)\n",
    "d.maximize_window()\n",
    "html = d.page_source\n",
    "\n",
    "select = Select(d.find_element_by_class_name('si-season-change'))\n",
    "\n",
    "data=[]\n",
    "cols = ['Season', 'Date', 'Time', 'Status', 'Team1', 'Score1', 'Team2', 'Score2', 'Venue', 'Match-Results']\n",
    "\n",
    "for each_indx in range(1,7):\n",
    "    select.select_by_index(each_indx)\n",
    "    time.sleep(5)\n",
    "    soup_1 = bs(d.page_source)\n",
    "    div_1= soup_1.find_all('div', {'class':'si-fix-box'})\n",
    "  \n",
    "    for each in div_1:\n",
    "        list1=[]\n",
    "        if each_indx==1:\n",
    "            list1.append('Season 6')\n",
    "        elif each_indx==2:\n",
    "            list1.append('Season 5')\n",
    "        elif each_indx==2:\n",
    "            list1.append('Season 4')\n",
    "        elif each_indx==2:\n",
    "            list1.append('Season 3')\n",
    "        elif each_indx==2:\n",
    "            list1.append('Season 2')\n",
    "        else:\n",
    "            list1.append('Season 1')\n",
    "    \n",
    "        list1.append(each.find('div', {'class':'matDate'}).text.strip('\\n'))\n",
    "        list1.append(each.find('div', {'class':'matTime'}).text.strip('\\n'))\n",
    "        list1.append(each.find('div', {'class':'matStatus'}).text.strip('\\n'))\n",
    "        list1.append(\"\".join(each.find_all('div', {'class':'fix-teamName'})[0].find('div', {'class':'si-fullName'}).text.split('\\n')))\n",
    "        list1.append(each.find('div', {'class':'matScore'}).find_all('span', {'class': 'si-score'})[0].text.strip())\n",
    "        list1.append(\"\".join(each.find_all('div', {'class':'fix-teamName'})[1].find('div', {'class':'si-fullName'}).text.split('\\n')))\n",
    "        list1.append(each.find('div', {'class':'matScore'}).find_all('span', {'class': 'si-score'})[1].text.strip())\n",
    "        list1.append(each.find('div', {'class':'mat-venue'}).text.strip('\\n'))\n",
    "        list1.append(each.find('div', {'class':'mat-resultStatus'}).text.strip('\\n'))\n",
    "        data.append(list1)\n",
    "\n",
    "match_res = pd.DataFrame(data=data, columns=cols)\n",
    "match_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HsR7QYHJky8z"
   },
   "outputs": [],
   "source": [
    "match_res.to_csv('match_res.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.get(schedule_link)\n",
    "time.sleep(5)\n",
    "d.maximize_window()\n",
    "html = d.page_source\n",
    "\n",
    "select = Select(d.find_element_by_class_name('si-season-change'))\n",
    "select.select_by_index(0)\n",
    "time.sleep(5)\n",
    "\n",
    "select_1 = Select(d.find_element_by_class_name('si-months-change'))\n",
    "data=[]\n",
    "cols = ['Season', 'Date', 'Time', 'Status', 'Team1', 'Score1', 'Team2', 'Score2', 'Venue', 'Match-Results']\n",
    "\n",
    "for each_indx in range(1,5):\n",
    "  \n",
    "    select_1.select_by_index(each_indx)\n",
    "    time.sleep(5)\n",
    "    soup_1 = bs(d.page_source)\n",
    "    div_1= soup_1.find_all('div', {'class':'si-fix-box'})\n",
    "  \n",
    "    for each in div_1:\n",
    "        list1 = []\n",
    "        list1.append('Season 7')\n",
    "    \n",
    "        list1.append(each.find('div', {'class':'matDate'}).text.strip('\\n'))\n",
    "        list1.append(each.find('div', {'class':'matTime'}).text.strip('\\n'))\n",
    "        list1.append(each.find('div', {'class':'matStatus'}).text.strip('\\n'))\n",
    "        list1.append(\"\".join(each.find_all('div', {'class':'fix-teamName'})[0].find('div', {'class':'si-fullName'}).text.split('\\n')))\n",
    "        list1.append(each.find('div', {'class':'matScore'}).find_all('span', {'class': 'si-score'})[0].text.strip())\n",
    "        list1.append(\"\".join(each.find_all('div', {'class':'fix-teamName'})[1].find('div', {'class':'si-fullName'}).text.split('\\n')))\n",
    "        list1.append(each.find('div', {'class':'matScore'}).find_all('span', {'class': 'si-score'})[1].text.strip())\n",
    "        list1.append(each.find('div', {'class':'mat-venue'}).text.strip('\\n'))\n",
    "        list1.append(each.find('div', {'class':'mat-resultStatus'}).text.strip('\\n'))\n",
    "        data.append(list1)\n",
    "\n",
    "match_sch = pd.DataFrame(data=data, columns=cols)\n",
    "match_sch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_sch.to_csv('match_sch.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CqP3fkNuoX1p"
   },
   "source": [
    "### Extract Player stats from Pro Kabaddi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "colab_type": "code",
    "id": "-UAtcvWmo53L",
    "outputId": "4bea3f85-edc1-471b-8afd-0acbbaea29bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_metrics</th>\n",
       "      <th>player_stats_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total Points</td>\n",
       "      <td>https://www.prokabaddi.com/stats/49-102-total-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raid Points</td>\n",
       "      <td>https://www.prokabaddi.com/stats/49-22-raid-po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tackle Points</td>\n",
       "      <td>https://www.prokabaddi.com/stats/49-103-tackle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Successful Raids</td>\n",
       "      <td>https://www.prokabaddi.com/stats/49-21-success...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super Raids</td>\n",
       "      <td>https://www.prokabaddi.com/stats/49-104-super-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Super 10s</td>\n",
       "      <td>https://www.prokabaddi.com/stats/49-100-super-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Successful Tackles</td>\n",
       "      <td>https://www.prokabaddi.com/stats/49-23-success...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Super Tackles</td>\n",
       "      <td>https://www.prokabaddi.com/stats/49-28-super-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>High 5s</td>\n",
       "      <td>https://www.prokabaddi.com/stats/49-101-high-5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        player_metrics                                   player_stats_url\n",
       "0         Total Points  https://www.prokabaddi.com/stats/49-102-total-...\n",
       "1          Raid Points  https://www.prokabaddi.com/stats/49-22-raid-po...\n",
       "2        Tackle Points  https://www.prokabaddi.com/stats/49-103-tackle...\n",
       "3     Successful Raids  https://www.prokabaddi.com/stats/49-21-success...\n",
       "4          Super Raids  https://www.prokabaddi.com/stats/49-104-super-...\n",
       "5            Super 10s  https://www.prokabaddi.com/stats/49-100-super-...\n",
       "6   Successful Tackles  https://www.prokabaddi.com/stats/49-23-success...\n",
       "7        Super Tackles  https://www.prokabaddi.com/stats/49-28-super-t...\n",
       "8              High 5s  https://www.prokabaddi.com/stats/49-101-high-5..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.get(stats_all)\n",
    "time.sleep(5)\n",
    "d.maximize_window()\n",
    "html = d.page_source\n",
    "\n",
    "\n",
    "soup = bs(html, 'html.parser')\n",
    "#Player stats links with respect to its matrics\n",
    "playerstat_div = soup.find_all('div', {'class': 'si-leadBoard-box'})\n",
    "metrics = [each.text.split('\\n')[3] for each in playerstat_div]\n",
    "\n",
    "player_stats_urls = []\n",
    "for each in playerstat_div:\n",
    "    player_stat = each.find('div', {'class': 'si-leadBoard-viewMore'})\n",
    "    player_stats_urls.append(main_url + player_stat.find('a').attrs['href'])\n",
    "\n",
    "player_stats_det = pd.DataFrame()\n",
    "player_stats_det['player_metrics'] = metrics\n",
    "player_stats_det['player_stats_url'] = player_stats_urls\n",
    "player_stats_det\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TOPHOPdepGiV"
   },
   "outputs": [],
   "source": [
    "player_stats_det.to_csv('player_stats_urls.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FM85t-dVogsm",
    "outputId": "0956d730-f0a8-4202-e0f7-ed42a3847aa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.prokabaddi.com/stats/49-102-total-points-statistics\n",
      "SEASON 7\n",
      "171\n",
      "SEASON 6\n",
      "186\n",
      "SEASON 5\n",
      "181\n",
      "SEASON 4\n",
      "104\n",
      "SEASON 3\n",
      "122\n",
      "SEASON 2\n",
      "128\n",
      "SEASON 1\n",
      "96\n",
      "https://www.prokabaddi.com/stats/49-22-raid-points-statistics\n",
      "SEASON 7\n",
      "112\n",
      "SEASON 6\n",
      "125\n",
      "SEASON 5\n",
      "122\n",
      "SEASON 4\n",
      "71\n",
      "SEASON 3\n",
      "84\n",
      "SEASON 2\n",
      "88\n",
      "SEASON 1\n",
      "71\n",
      "https://www.prokabaddi.com/stats/49-103-tackle-points-statistics\n",
      "SEASON 7\n",
      "144\n",
      "SEASON 6\n",
      "154\n",
      "SEASON 5\n",
      "150\n",
      "SEASON 4\n",
      "80\n",
      "SEASON 3\n",
      "99\n",
      "SEASON 2\n",
      "107\n",
      "SEASON 1\n",
      "85\n",
      "https://www.prokabaddi.com/stats/49-21-successful-raids-statistics\n",
      "SEASON 7\n",
      "105\n",
      "SEASON 6\n",
      "119\n",
      "SEASON 5\n",
      "112\n",
      "SEASON 4\n",
      "67\n",
      "SEASON 3\n",
      "78\n",
      "SEASON 2\n",
      "83\n",
      "SEASON 1\n",
      "70\n",
      "https://www.prokabaddi.com/stats/49-104-super-raids-statistics\n",
      "SEASON 7\n",
      "40\n",
      "SEASON 6\n",
      "57\n",
      "SEASON 5\n",
      "54\n",
      "SEASON 4\n",
      "28\n",
      "SEASON 3\n",
      "28\n",
      "SEASON 2\n",
      "33\n",
      "SEASON 1\n",
      "29\n",
      "https://www.prokabaddi.com/stats/49-100-super-10s-statistics\n",
      "SEASON 7\n",
      "34\n",
      "SEASON 6\n",
      "31\n",
      "SEASON 5\n",
      "33\n",
      "SEASON 4\n",
      "15\n",
      "SEASON 3\n",
      "17\n",
      "SEASON 2\n",
      "16\n",
      "SEASON 1\n",
      "20\n",
      "https://www.prokabaddi.com/stats/49-23-successful-tackles-statistics\n",
      "SEASON 7\n",
      "144\n",
      "SEASON 6\n",
      "154\n",
      "SEASON 5\n",
      "150\n",
      "SEASON 4\n",
      "80\n",
      "SEASON 3\n",
      "99\n",
      "SEASON 2\n",
      "107\n",
      "SEASON 1\n",
      "85\n",
      "https://www.prokabaddi.com/stats/49-28-super-tackles-statistics\n",
      "SEASON 7\n",
      "83\n",
      "SEASON 6\n",
      "92\n",
      "SEASON 5\n",
      "87\n",
      "SEASON 4\n",
      "41\n",
      "SEASON 3\n",
      "42\n",
      "SEASON 2\n",
      "48\n",
      "SEASON 1\n",
      "49\n",
      "https://www.prokabaddi.com/stats/49-101-high-5s-statistics\n",
      "SEASON 7\n",
      "38\n",
      "SEASON 6\n",
      "44\n",
      "SEASON 5\n",
      "41\n",
      "SEASON 4\n",
      "21\n",
      "SEASON 3\n",
      "21\n",
      "SEASON 2\n",
      "30\n",
      "SEASON 1\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "main_data = []\n",
    "p = 0\n",
    "for each_url in player_stats_det['player_stats_url']:\n",
    "    print(each_url)\n",
    "    d.get(each_url)\n",
    "    time.sleep(5)\n",
    "    d.maximize_window()\n",
    "    element = d.find_element_by_id('player_Btn')\n",
    "    element.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    select = Select(d.find_element_by_id('season_dropdown'))\n",
    "  \n",
    "    options_det = [o.text for o in select.options]\n",
    "    data1 = []\n",
    "    for each_index in range(1, len(options_det)):\n",
    "        print(options_det[each_index])\n",
    "        select.select_by_index(each_index)\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        load_more = d.find_element_by_id('load_more')\n",
    "    \n",
    "        while load_more:\n",
    "            try:\n",
    "                load_more.click()\n",
    "                time.sleep(5)\n",
    "                d.maximize_window()\n",
    "                load_more = d.find_element_by_id('load_more')\n",
    "            except ElementNotInteractableException:\n",
    "                break\n",
    "\n",
    "        soup_1 = bs(d.page_source)\n",
    "    \n",
    "        #player_cols_div = soup_1.find('div',attrs={'class':'si-leadBoard-detail-tRow'})\n",
    "        #player_cols_div_det = player_cols_div.find_all('div',attrs={'class':'si-leadBoard-detail-tCol'})\n",
    "        #print(len(player_cols_div_det))\n",
    "        #newcols = [each.text.split('\\n')[2] for each in player_cols_div_det]\n",
    "        #print(newcols)\n",
    "    \n",
    "        player_div = soup_1.findAll('div',attrs={'class':'sipk-lb-detailItem'})\n",
    "\n",
    "    \n",
    "        print(len(player_div))\n",
    "        data = []\n",
    "        for each in player_div:\n",
    "            list1 = []\n",
    "      \n",
    "            list1.append(options_det[each_index])\n",
    "            list1.append(player_stats_det['player_metrics'][p])\n",
    "      \n",
    "            pdet = each.find('div', {'class':'sipk-lb-playerName'})\n",
    "            if pdet:\n",
    "                list1.append(pdet.text.split('\\n')[3].strip())\n",
    "            else:\n",
    "                list1.append(np.NAN)\n",
    "\n",
    "            pdet = each.find('a', {'class':'sipk-lb-team'})\n",
    "            if pdet:\n",
    "                list1.append(\" \".join(pdet.attrs['href'].split('/')[2].split('-')[0:2]))\n",
    "            else:\n",
    "                list1.append(np.NAN)\n",
    "\n",
    "            pdet = each.find('div', {'class':'sipk-lb-matchedPlayed'})\n",
    "            if pdet:\n",
    "                list1.append(pdet.text.split('\\n')[1])\n",
    "            else:\n",
    "                list1.append(np.NAN)\n",
    "\n",
    "            pdet = each.find('div', {'class':'sipk-lb-raidPoints'})\n",
    "            if pdet:\n",
    "                list1.append(pdet.text.split('\\n')[1])\n",
    "            else:\n",
    "                list1.append(np.NAN)\n",
    "\n",
    "            pdet = each.find('div', {'class':'sipk-lb-playerprofile'})\n",
    "            if pdet:\n",
    "                list1.append(pdet.text.split('\\n')[1].strip())\n",
    "            else:\n",
    "                list1.append(np.NAN)\n",
    "\n",
    "            data.append(list1)\n",
    "\n",
    "        data1.append(data)\n",
    "    main_data.append(data1)\n",
    "    p = p + 1\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LhVOY1udqFDO",
    "outputId": "029c7b43-a2ab-4210-fe54-d7dfeec3e7b9"
   },
   "outputs": [],
   "source": [
    "main_data_final = []\n",
    "for x in main_data:\n",
    "    for y in x:\n",
    "        for z in y:\n",
    "            main_data_final.append(z)\n",
    "    \n",
    "cols = ['Season_Name', 'Metrics', 'Player_Name', 'Team_Name', 'Total_matches_played', 'Points', 'Player_type']\n",
    "player_stat = pd.DataFrame(data=main_data_final, columns=cols)\n",
    "\n",
    "player_stat.to_csv('player_stat.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standings for each team in current season as of now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.prokabaddi.com/standings\n"
     ]
    }
   ],
   "source": [
    "soup = bs(response.text, 'html.parser')\n",
    "divhead = soup.find('div', {'class': 'nav-middle'})\n",
    "divli = divhead.find('li', {'class': 'standings'}).find('a').attrs['href']\n",
    "standings_link = main_url + divli\n",
    "print(standings_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.get(standings_link)\n",
    "time.sleep(5)\n",
    "d.maximize_window()\n",
    "html = d.page_source\n",
    "\n",
    "select = Select(d.find_element_by_id('season_selectBox'))\n",
    "time.sleep(5)\n",
    "\n",
    "data=[]\n",
    "cols = ['Season', 'Rank', 'Team_Name', 'Matches_Played', 'Matches_Won', 'Matches_Lost', 'Matches_Drow', 'Total_Points']\n",
    "\n",
    "select.select_by_index(0)\n",
    "time.sleep(5)\n",
    "d.maximize_window()\n",
    "soup_1 = bs(d.page_source)\n",
    "div_1= soup_1.find_all('div', {'class':'sipk-standing-dataRow'})\n",
    "  \n",
    "for each in div_1:\n",
    "    list1 = []\n",
    "    list1.append('Season 7')\n",
    "      \n",
    "    list1.append(each.find('div', {'class':'sipk-rank'}).text.strip('\\n').split('\\n')[0])\n",
    "    list1.append(each.find('div', {'class':'sipk-team'}).text.strip('\\n'))\n",
    "    list1.append(each.find('div', {'class':'sipk-play'}).text.strip('\\n'))\n",
    "    list1.append(each.find('div', {'class':'sipk-won'}).text.strip('\\n'))\n",
    "    list1.append(each.find('div', {'class':'sipk-lost'}).text.strip('\\n'))\n",
    "    list1.append(each.find('div', {'class':'sipk-drow'}).text.strip('\\n'))\n",
    "    list1.append(each.find('div', {'class':'sipk-points'}).text.strip('\\n'))\n",
    "\n",
    "    data.append(list1)\n",
    "\n",
    "team_rank = pd.DataFrame(data=data, columns=cols)\n",
    "team_rank.to_csv('team_rank.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Hackathon_Final_Palak.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
